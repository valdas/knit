<h1>Test-Driven Development (in KNIT)</h1>

<ul>
<li> <a href="#1">Introduction</a>
<ul>
<li> <a href="#2">The Need to Test</a>
<li> <a href="#3">Test-Driven Development (TDD)</a>
<li> <a href="#4">Demo-Driven Development</a>
</ul></ul>

<a name="1"></a><h2>Introduction</h2>

<a name="2"></a><h3>The Need to Test</h3>
<p>
<em>I should be able to write a test in any language. --J. Random Hacker.</em>
</p>
<p>
<a href="``share``img/bug.jpg">
<img src="``share``/img/bug.jpg" width=300 align=right></a>
If there is anything that is constant across all programming languages,
it is the need to test the code. Every programming has to be debugged.
</p>
<ul>
<li> "Debugging had to be discovered. I can remember the exact instant when I realized that a large part of my life from then on was going to be spent in finding mistakes in my own programs.<br>-- Maurice Wilkes, 1949
</ul>
<p>
Wilkes is pointing out that the time required to debug a system is
surprisingly large- over half the effort of building.  According to
Brooks (The Mythical Man Month, 1995), the time required to build
software divides as follows:
</p>
<ul>
<li> 1/3 in management and planning
<li> 1/6 in development
<li> 1/4 in unit test (testing all parts in isolation)
<li> 1/4 in system testing (testing all parts, in combination) 
</ul>
<p>
Decades later, the same distribution persists. It looks like this (the fractions
indicate how much of the development time is consumed by each activity):
<center>
<img width=400 src="``share``/img/vdiagram.png">
</center>
</p>
<p>
For years I researched ways to reduce the cost of testing. With David
Owen, we tried some AI techniques for searching formal models for
violations to temporal logic queries.  With several other graduate
students (most notably, Justin diStefano) we tried data mining methods
to predict where to best focus the testing effort. All cool stuff, to
be sure, but the basic economics message of the above "v-diagram"
remains: testing consume around half your development time.
</p>
<a name="3"></a><h3>Test-Driven Development (TDD)</h3>
<p>
Kent Beck has decided to turn a vice into a virtue.  I read his
"test-driven development" (TDD) approach as something like this:
</p>
<ul>
<li> Granted: we will spend most of our development time testing the code.
<li> Consequently: redesign the development process around testing.
</ul>
<p>
In TDD, the <em>first</em> thing a programmer does on a new project is to
write a test that fails (the idea is to ensure that the test really
works and can catch an error).
Also, ideally, the programmer ends her day with a broken test. Next morning,
the first thing she does is run that test again, then works on fixing it.
This reduces the time requied to "swap in" at the start of the day.
</p>
<p>
TDD has rules:
</p>
<ul>
<li> PLANNING rules
<ul>
<ul>
<li> User stories are written. (a.k.a. lots of demos)
<li> Make frequent small releases (a.k.a. shows a string of demos)
<li> Fix it when it breaks (ak.a. code run break fix is the usual cycle)
</ul>
</ul>
<li> CODING rules
<ul>
<ul>
<li> Code the unit test first.
</ul>
</ul>
<li> TESTING rules
<ul>
<ul>
<li> All code must have unit tests.
<li> All code must pass all unit tests before it  can be released.
<li> When a bug is found tests are created.
<li> Acceptance tests are run often and the score is published.
</ul></ul></ul>
<p>
A shorter way of saying the above is this: red, green, refactor.
</p>
<ul>
<li> Red: find failed tests;
<li> Green: fix them;
<li> Refactor: sometimes, use the experience gained from all this testing  to reorganize and improve the code base.
</ul>
<p>
Two principles of TDD are "keep it simple, stupid" (KISS) and "You
ain't gonna need it" (YAGNI). By focusing on writing only the code
necessary to pass tests, designs can be cleaner and clearer than is
often achieved by other methods.  In
<a href="http://www.amazon.com/gp/product/0321146530/103-2564761-2872664?v=glance&n=283155">Test-Driven Development by Example</a>, Kent Beck also suggests the
principle "Fake it, till you make it".
</p>
<a name="4"></a><h3>Demo-Driven Development</h3>
<p>
After reading Kent Beck's book "Test-driven development by Example", I
was struck with how small each test was. When checking oeprations on a
new abstract data type, just mini-tests are certainly
appropriate. However, when working with large granularity programs
(e.g. shell scripts), Kent-style tests seemed to small.
</p>
<p>
So in my mind,  I run a (small) variation to TDD. Think about how you might
present the code to someone else:
</p>
<ul>
<li> what you'd show off;
<li>  what you'd use to demonstrate the core principles. 
</ul>
<p>
This variant is called
"demo-driven development" and it differs from TDD in that each "demo"
is usually a seperate script comprising "large-grain tests" that
demonstrate some functionality.
Where as TDD demands thousands of tests,
DDD (demo-driven development) demands dozens (or less) of demonstration scripts.
